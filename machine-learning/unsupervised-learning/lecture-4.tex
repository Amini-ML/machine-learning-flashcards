%Front; Back
\documentclass{article}
\begin{document}

What does 'Markov' refer to (in Markov models)?; \begin{itemize} \item A conditional independence relationship.  \item Markov property: given the present observation, the future is independent of the past.  \end{itemize}

State one overall and three more specific goals of latent variable models for time series.; \begin{itemize} \item Gen: built joint probabilistiic model of the data $p(\mathbf{x_1,...x_n}$.  \item Predict $p(x_t|x_1,...,x_{t-1})$ \item Detect abnormal changed behaviour (if $p(x_t, x_{t+1}, ...|x_1,...,x_{t-1})$ small) \item Recover underlying / latent / hidden causes linking entire sequence.  \end{itemize}

Write an expression for the joint of latent chain (Markov) models.; \begin{itemize} \item $P(z_{1:T}, x_{1:T}) = P(z_t)P(x_t|z_t)\prod_{t=2}^TP(z_t|z_{t-1})P(x_t|z_t)$ \item $x$ and $z$ real-valued vectors.  \end{itemize} 

Name two frequently-used tractable latent chain models.; \begin{itemize} \item Linear Gaussian state-space models \item Hidden Markov models.  \end{itemize}

Describe the setup of a LGSSM; \begin{itemize} \item All conditional distributions are linear and gaussian.  \item Output eqn: $\mathbf{x_t}=C\mathbf{z}_t+\mathbf{v}_t$ \item State dynamics equation $\mathbf{z}_t=A\mathbf{z}_{t-1}+\mathbf{w}_t$ \item $\mathbf{v}_t \sim N(0,\sigma^2_v)$ \item $\mathbf{w}_t \sim N(0,\sigma^2_w)$ \item $\mathbf{z}_t$ is multivariate Gaussian. So joint $p(\mathbf{x}_{1:T}, \mathbf{z}_{1:T})$ is one big multivariate Gaussian.  \end{itemize}

Compare factor analysis and time-series state-space models.; \begin{itemize} \item Very similar, with $z_{t,j}$ (SSM) replacing $z_j$ in FA.  \item Sim: observations confined near low-dim subspace.  \item Diff: Successive observations generated from correlated points in the latent space (vs iid).  \item Diff: FA requires latent dim $K<D$ and $\Psi$ diagonal. SSM may have $K\geq D$ and arbitrary output noise. Because number of elements in covariance matrix (across time, TODO is x?) is much larger.  \item Thus ML estimates of subspace FA and SSM may differ.  \end{itemize}

Will ML estimates of subspaces (same K) necessarily be the same?; \begin{itemize} \item No.  \item Diff: FA requires latent dim $K<D$ and $\Psi$ diagonal. SSM may have $K\geq D$ and arbitrary output noise. Because number of elements in covariance matrix (across time, TODO is x?) is much larger.  \item Thus ML estimates of subspace FA and SSM may differ.  \end{itemize} 

Name two ways of interpreting SSMs (i.e. linking them to other models).; \begin{itemize} \item Factor analysis where successive observations are generated from correlated points in the latent space.  \item Markov chain with linear (perturbed) dynamics in latents and linear projection to observations.  \end{itemize}

Describe the interpretation of SSMs relating to Markov chains.; \begin{itemize} \item Markov chain with linear dynamics in latents, \item Markov chain in latents perturbed by Gaussian innovations noise (may describe stochasticity, unknown control, or model mismatch.) \item Obs are a linear projection of the dynamical state, with additive iid Gaussian noise.  \end{itemize}

In a SSM, can the observations be of higher dimension than the latents? How about in factor analysis?; \begin{itemize} \item Yes for SSM, no for FA.  \end{itemize}

Write down an example of equations for a state space model with control inputs.; \begin{itemize} \item Inputs $u_t$, Outputs $x_t$.  \item State dynamics equation: $z_t=Az_{t-1}+Bu_{t-1}+w_t$ \item Output equation: $x_t=Cz_t+Du_t+v_t$ \end{itemize}

Describe the setup of Hidden Markov Models. (including equations); \begin{itemize} \item Discrete hidden state $s_t\in \{1,...,K\}$ \item Joint $p(s_{1:T}, \mathbf{x}_{1:T})=P(s_1)P(\mathbf{x}_1|s_1)\prod_{t=2}^TP(s_t|s_{t-1})P(\mathbf{x_t}|s_t)$ \item Initial state probs $\pi_j = P(s_1=j)$ \item Transition matrix $\Phi_{ij}=P(s_{t+1}=j|s_t=i)$ \item Emission (output) dists $A_i(\mathbf{x})=P(\mathbf{x}_t=\mathbf{x}|s_t=j)$ (continuous $\mathbf{x}_t$) \item or $A_{jk}=P(\mathbf{x}_t=k|s_t=j)$ for discrete $\mathbf{x}_t$.  \end{itemize}

Write down the joint for input-outut HMMs.; \begin{itemize} \item $p(s_{1:T}, \mathbf{x}_{1:T}|u_{1:T})=P(s_1|u_1)P(\mathbf{x}_1|s_1, u_1)\prod_{t=2}^TP(s_t|s_{t-1}, u_{t-1})P(\mathbf{x_t}|s_t, u_t)$ \end{itemize}

Briefly discuss the practicality and modelling capacity of input-output HMMs.; \begin{itemize} \item Can capture arbitrarily complex input-output relationships \item but number of states required is often impractical.  \end{itemize} 

Briefly discuss input-output HMMs.; \begin{itemize} \item Can capture arbitrarily complex input-output relationships \item But number of states required is often impractical.  \end{itemize}

State one advantage and one disadvantage of LGSSMs compared to HMMs.; \begin{itemize} \item Adv: Continuous vector state is a powerful representation: a real-valued state vector can store an arbitrary number of bits in principle (vs $2^N$ states to comm N bits of information for an HMM (since states discrete, i.e. bin).) \item Disadv: LG output/dynamics are very weak: can capture v limted dynamics. HMMs can in principle represent arbitrary stochastic dynamics and output mappings.  \end{itemize}

Name at least one HMM with richer state representation than a plain HMM.; \begin{itemize} \item Factorial HMMs \item Dynamic Bayesian networks. (TODO: what is this?) \end{itemize}

Do observations $x_t$ in a HMM need to be Markov?; No.

In a HMM, is $x_1$ independent of $x_3$ conditioned on $x_2$?; Not necessarily.

Why use the Markov assumption in the latents in HMMs?; \begin{itemize} \item Cond indep makes computation much easier.  \item Because data may be partially observed: e.g. classical physics local in time(?), working out what's really out there in the world \end{itemize}

Name two interpretations of HMMs; \begin{itemize} \item Markov chain with stochastic measurements (focus on latents $s_{1:T}$ \item Mixture model with states coupled over time ($s_t, x_t$ together) \end{itemize}

For an HMM, is the output process Markov of some order?; Not necessarily.

Can we use discrete state, discrete output models (HMMs) to approximate nonlinear continuous dynamics and observation mappings?; Yes, but this is usually not practical. 

TODO: what are stochastic finite state machines / automata?; (mentioned in a one-liner)

Briefly discuss the  information one (continuous) state can hold.; Depends on the noise magnitude. 

Compare the modelling capacity of HMM dynamics and linear Gaussian dynamics with respect to fixed points.; \begin{itemize} \item HMM can converge to >1 fixed points e.g. with cycles.  \item LGSSM can only converge to one or a line of fixed points.  \end{itemize}

Name one extension of HMMs; \begin{itemize} \item (*) Switching state space models \item Hierarchical models \item Constrained HMMs \item Continuous state models with discrete outputs for time series and static data \item (as long as you remember the first one it's fine) \end{itemize}

Describe the setup of Linear Gaussian SSMs. (including equations); \begin{itemize} \item Gaussian hidden state $z_t \sim N(\mathbf{\mu_0}, Q_0)$ 
\item Transition dynamics $\mathbf{z_t|z_{t-1}}\sim  N(A\mathbf{z_{t-1}}, Q)$ \item Emission (output) dists $\mathbf{x_t|z_t}\sim N(C\mathbf{z}_t, R)$.  
\item Joint $P(\mathbf{x_1,...,x_T,z_1,...,z_T})=P(\mathbf{z_1})\prod_{t=2}^T P(\mathbf{z_t|z_{t-1}})\prod_{t=1}^T P(\mathbf{x_t|z_t})$
\end{itemize}

What information do we need when doing maximum likelihood learning with EM for LGSSMs?; \begin{itemize}
    \item Expectations needed in E-step are derived from singleton and pairwise marginals
    \item (Likewise only need singleton and pairwise expectations on q for M-step? TODO check)
    \item Since we can break down the log joint into pieces (since the joint has a factored structure.)
\end{itemize}

Discuss how factored structure helps reduce computational cost in LGSSM models.; \begin{itemize}
    \item Don't need to invert matrix $(TK^3)$ cost (TODO: what matrix? Cov?)
    \item Only need subpieces
    \item And matrix has structure, can invert without explicit inversion.
    \item (from notes, slide 16 ML learning with EM)
\end{itemize}

Name three general inference problems (and one more problem) in chain models; \begin{itemize}
    \item Filtering: $P(\mathbf{z_t|x_1,...,x_t})$
    \item Smoothing: $P(\mathbf{z_t|x_1,...,x_T})$ 
    \item (Also $P(\mathbf{z_t, z_{t-1}|x_1,...,x_T})$ for learning)
    \item Prediction: $P(\mathbf{z_t|x_1,...,x_{t-\Delta t}})$
\end{itemize}

Describe filtering; \begin{itemize}
    \item Identify distribution on latents using data up till current time
    \item 
    $P(\mathbf{z_t|x_1,...,x_t})$
\end{itemize}

Describe smoothing; \begin{itemize}
    \item Identify distribution of latent using all data. \item (Future information is informative about the past, e.g. given an airplane can't `jump', future radar data informative of where it is now.)
    \item $P(\mathbf{z_t|x_1,...,x_T})$
\end{itemize}

What integral may we have to calculate to evaluate $P(\mathbf{z_t|x_1,...,x_t})$? What makes us able to evaluate these in latent chain models?; \begin{itemize}
    \item $P(\mathbf{z_t|x_1,...,x_t}) = \int ...\int d\mathbf{z_1}...d\mathbf{z_{t-1}}P(\mathbf{y_1},...,\mathbf{y_t}|\mathbf{x_1},...,\mathbf{x_t}$
    \item But the factored structure of the distributions will help us.
    \item The algorithms rely on a form of temporal updating or message passing.
\end{itemize}

Describe a naive vs the dynamic programming way of finding $P(s_k|\mathbf{x_1,...,x_t}$. \begin{itemize}
    \item Naive: start one bug at each state holding, copy bug to each subsequent state, multiply by transition x output emission prob, sum all bugs per state at end timestep. (Rough description will do)
    \item FYI expression is $P(s_t=k|\mathbf{x_1,...,x_t})=\sum_{k_1, ..., k_{t-1}}P(s_1=k_1,...,s_t=k|\mathbf{x_1,...,x_t}\propto\sum_{k_1,...,k_{t-1}}\pi_{k_1}A_{k_1}\mathbf{x_1}\phi_{k_1,k_2}A_{k_2}(\mathbf{x_2})...\phi_{k_{t-1},k}A_k(\mathbf{x_t})$
    \item Recursive (DP): at every timestep, replace bugs at each node with a single bug carrying the sum of values.
\end{itemize}

Write down/derive the recursive formula for calculating $P(\mathbf{z_t}|x_{1:t})$; \begin{itemize}
    \item $P(\mathbf{z_t}|x_{1:t})$
    \item $=\int P(\mathbf{z_t, z_{t-1}|x_t, x_{1:t-1}})d\mathbf{z_{t-1}}$
    \item $=\int \frac{P(\mathbf{z_t, z_{t-1}|x_t, x_{1:t-1}})}{P(\mathbf{x_t|x_{1:t-1}}}d\mathbf{z_{t-1}}$ (Bayes' Rule)
    \item $\propto\int P(\mathbf{x_t| z_t, z_{t-1}, x_{1:t-1}})P(\mathbf{z_t|z_{t-1}, x_{1:t-1}}) P(\mathbf{z_{t-1}|x_{1:t-1}}) d\mathbf{z_{t-1}}$
    \begin{itemize}
        \item Factor out $z_t, z_{t-1}$
        \item consider only numerator
    \end{itemize}
    \item $=\int P(\mathbf{x_t| z_t})P(\mathbf{z_t|z_{t-1}}) P(\mathbf{z_{t-1}|x_{1:t-1}}) d\mathbf{z_{t-1}}$
    \begin{itemize}
        \item First term: $x_t$ conditionally independent of $z_{t-1}, x_{1:t-1}$ given $z_t$
        \item second term: $z_t$ cond indep of $x_{1:t-1}$ given $y_{t-1}$.
    \end{itemize}
    \item This is a forward recursion based on Bayes' rule. 
    \item (Complexity of update depends on dim of state and dists involved.)
\end{itemize}

Write down the formulae for the HMM forward pass and state the time complexity.; \begin{itemize}
    \item Define $\alpha_t(i)=P(\mathbf{x_1,...,x_t}, s_t=i|\theta)$
    \begin{itemize}
        \item Note: this is a joint vs a posterior. Can obtain posterior by normalising (divide by $\sum_k \alpha_t(k)$.)
    \end{itemize}
    \item then $\alpha_1(i)=P(s_1=i)P(x_1|s_1=i)=\pi_iA_i(\mathbf{x_1})$,
    \item $\alpha_{t+1}(i)=\big(\sum_{j=1}^K\alpha_t(j)\Phi_{ji}\big)A_i(\mathbf{x}_{t+1})$.
    \begin{itemize}
        \item $\Phi_{ji}=P(s_{t+1}=i|s_t=j)$
        \item i.e. term in brackets is $
        P(s_{t+1}=i, \mathbf{x_1,...,x_t}|\theta)$.
        \item $A_i(\mathbf{x}_{t+1})=P(x_{t+1}|s_{t+1}=i)$.
    \end{itemize}
    \item Compute likelihood: $P(\mathbf{x_1,...,x_T}|\theta)=\sum_{s_1,...,s_T}P(\mathbf{x_1,...,x_T}, s_1,...,s_T,\theta)=\sum_{k=1}^K\alpha_T(k)$.
    \begin{itemize}
        \item $=\sum_{k=1}^KP(s_T=k, \mathbf{x_1,...,x_T}|\theta)$
    \end{itemize}
    \item Time complexity: $O(TK^2)$ vs naive sum $O(K^T)$
\end{itemize}

Briefly describe Kalman filtering (TODO check when finished going through L4); \begin{itemize}
    \item (1) Propose new belief about state $P(\mathbf{y_t|x_{1:t-1}})$.
        \item (2) Incorporate new datapoint $P(\mathbf{y_t|x_{1:t}})$.
        \item Preds look at prev prediction error, error affects est of state mean with some scaling (Kalman gain).
    \item Model:
    \begin{itemize}
        \item MSE est of state 
    \begin{itemize}
        \item Corr between Gaussian p(0) dist and MSE bc likelihood of Gaussian is squared error
    \end{itemize}
    \item where state process is linear, 
    \begin{itemize}
        \item (Correct posterior beliefs for Fourier?)
    \end{itemize}
    \item without specifying the noise
    \end{itemize}
    
\end{itemize}

State the equation for $P(\mathbf(y_1|x_1)$ for Kalman Filtering (LGSSM); \begin{itemize}
    \item Model: \begin{itemize}
            \item $\mathbf{y_1}\sim N(\mathbf{\mu_0},Q_0)$
            \item $\mathbf{y_t|y_{t-1}}\sim N(A\mathbf{y}_{t-1}, Q)$
            \item $\mathbf{x_t|y_t}\sim N(C\mathbf{y_t},R)$
        \end{itemize}
    \item Let $\hat{\mathbf{y}}^0_1=\mathbf{\mu_0}$ and $\hat{V}^0_1=Q_0$. Then
    \begin{itemize}
        \item superscript: given data, subscript: timestep you're estimating
        \item Note V is posterior variance, not est var
    \end{itemize}
    \item $P(\mathbf{y_1|x_1})=N(\mathbf{\hat{y}_1^0+K_1(\mathbf{x_1}-C\hat{\mathbf{y}}^0_1}), \hat{V^0_1}-K_1C\hat{V}^0_1)=N(\mathbf{\hat{y}^1_1}, \hat{V}^1_1)$.
    \begin{itemize}
        \item Mean: mean in y space + (K: beta of y on x) $\times$ (deviation from mean in x).
        \item Var: TODO
        \item C maps y to x space.
        \item Kalman gain $K_1=\hat{V}^0_1C^T(C\hat{V}^0_1C^T+R)^{-1}$
    \end{itemize}
\end{itemize}
    
State the general update equations for Kalman Filtering (LGSSM); \begin{itemize}
    \item In general, we define $\hat{\mathbf{y}}^\tau_t \equiv E[\mathbf{y_t|x_1,...,x_\tau}]$ and $\hat{V}^\tau_t \equiv V[\mathbf{y_t}|x_1,...,x_\tau]$. Then
        \item (1) Propose new belief about state $P(\mathbf{y_t|x_{1:t-1}})=\int d\mathbf{y}_{t-1}P(\mathbf{y_t|y_{t-1}})P(\mathbf{y_{t-1}|x_{1:t-1}})=N(A\hat{y}^{t-1}_{t-1}, A\hat{V}^{t-1}_{t-1}A^T+Q)=N(\hat{\mathbf{y}}^{t-1}_t, \hat{V}^{t-1}_t)$.
        \item (2) Incorporate new datapoint $P(\mathbf{y_t|x_{1:t}})=N(\hat{\mathbf{y}}^{t-1}_t+K_t(\mathbf{x_t}-C\mathbf{\hat{y}}^{t-1}_t), \hat{V}^{t-1}_t - K_tC\hat{V}^{t-1}_t)=N(\mathbf{\hat{y}}^t_t, \hat{V}^t_t)$.
        \begin{itemize}
            \item Kalman gain $K_t = \hat{V}^{t-1}_tC^T(C\hat{V}^{t-1}_tC^T+R)^{-1} = \langle \mathbf{yx}^T \rangle \langle \mathbf{xx^T} \rangle^{-1}$
            \item Preds look at prev prediction error, error affects est of state mean with some scaling (Kalman gain)
        \end{itemize}
        \begin{itemize}
        \item superscript: given data, subscript: timestep you're estimating
        \item Note V is posterior var, not est var
    \end{itemize}
        \item Model: \begin{itemize}
            \item $\mathbf{y_1}\sim N(\mathbf{\mu_0},Q_0)$
            \item $\mathbf{y_t|y_{t-1}}\sim N(A\mathbf{y}_{t-1}, Q)$
            \item $\mathbf{x_t|y_t}\sim N(C\mathbf{y_t},R)$
        \end{itemize}
\end{itemize}

What is innovations noise in a LGSSM?; \begin{itemize}
    \item Noise in latent state transition
    \item i.e. Q in $\mathbf{y_t|y_{t-1}}\sim N(A\mathbf{y_{t-1}, Q})$.
\end{itemize}

% Bayesian Smoothing slide 27

\end{document}
